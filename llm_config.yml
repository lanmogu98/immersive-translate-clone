# LLM Provider & Model Configuration
# =============================================================================
# This is the single source of truth for all LLM configuration.
#
# Structure: provider_id -> provider_settings -> models -> model_details
#
# Provider Settings:
#   - api_key_env_var: Environment variable name for API key (for reference)
#   - api_base_url: API endpoint URL
#   - temperature: Default temperature (0.0 - 2.0)
#   - max_tokens: Maximum output tokens
#   - context_window: Maximum input context tokens
#   - pricing_currency: Currency for pricing ("$" or "짜")
#   - rate_limit (optional):
#       - min_interval_seconds: Minimum time between requests
#       - max_requests_per_minute: Max RPM (0 = unlimited)
#   - request_overrides (optional): Extra fields to include in API request
#
# Model Settings:
#   - id: Model identifier for API calls
#   - name: Display name in UI
#   - pricing: { input: X, output: Y } per 1M tokens
#
# Note: In browser extension, API keys are stored in chrome.storage (not env vars).
#       The api_key_env_var field is for documentation/reference only.
#
# To update the extension:
#   1. Edit this file
#   2. Run: npm run build:config
#   3. Reload the extension in Chrome
# =============================================================================

#-------------------------------------------------------------------------------
# Shared endpoints for reuse across providers (YAML anchors)
#-------------------------------------------------------------------------------
_shared_endpoints:
  volcengine: &volcengine_endpoint "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
  openrouter: &openrouter_endpoint "https://openrouter.ai/api/v1/chat/completions"

#-------------------------------------------------------------------------------
# Global Defaults
#-------------------------------------------------------------------------------
_defaults:
  temperature: 0.9

#-------------------------------------------------------------------------------
# Providers
#-------------------------------------------------------------------------------

deepseek-volcengine:
  name: "DeepSeek (Volcengine)"
  api_key_env_var: "DEEPSEEK_API_KEY_VOLC"
  api_base_url: *volcengine_endpoint
  max_tokens: 16000
  context_window: 128000
  pricing_currency: "짜"
  models:
    deepseek-v3.2:
      id: "deepseek-v3-2-251201"
      name: "DeepSeek V3.2"
      pricing: { input: 4.00, output: 6.00 }
    deepseek-r1:
      id: "deepseek-r1-250528"
      name: "DeepSeek R1"
      pricing: { input: 4.00, output: 12.00 }

gemini:
  name: "Google Gemini"
  api_key_env_var: "GEMINI_API_KEY"
  api_base_url: "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions"
  max_tokens: 65536
  context_window: 1000000
  pricing_currency: "$"
  models:
    gemini-2.5-flash:
      id: "gemini-2.5-flash"
      name: "Gemini 2.5 Flash"
      pricing: { input: 0.15, output: 0.60 }
    gemini-2.5-pro:
      id: "gemini-2.5-pro"
      name: "Gemini 2.5 Pro"
      pricing: { input: 1.25, output: 5.00 }

gemini-free:
  name: "Google Gemini (Free Tier)"
  api_key_env_var: "GEMINI_FT_API_KEY"
  api_base_url: "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions"
  max_tokens: 65536
  context_window: 1000000
  pricing_currency: "$"
  rate_limit:
    min_interval_seconds: 12.0
    max_requests_per_minute: 5
  models:
    gemini-2.5-flash-free:
      id: "gemini-2.5-flash"
      name: "Gemini 2.5 Flash (Free)"
      pricing: { input: 0.0, output: 0.0 }

qwen:
  name: "Alibaba Qwen"
  api_key_env_var: "QWEN_API_KEY"
  api_base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
  max_tokens: 32768
  context_window: 995904
  pricing_currency: "짜"
  models:
    qwen-plus:
      id: "qwen-plus"
      name: "Qwen Plus"
      pricing: { input: 0.80, output: 2.00 }
    qwen3-max:
      id: "qwen3-max"
      name: "Qwen3 Max"
      pricing: { input: 0.60, output: 24.00 }

zhipu:
  name: "Zhipu AI (GLM)"
  api_key_env_var: "ZHIPU_API_KEY"
  api_base_url: "https://open.bigmodel.cn/api/paas/v4/chat/completions"
  max_tokens: 128000
  context_window: 200000
  pricing_currency: "$"
  models:
    glm-4.5:
      id: "glm-4.5"
      name: "GLM-4.5"
      pricing: { input: 0.60, output: 2.20 }
    glm-4.6:
      id: "glm-4.6"
      name: "GLM-4.6"
      pricing: { input: 0.60, output: 2.20 }

doubao:
  name: "Doubao (Volcengine)"
  api_key_env_var: "DOUBAO_API_KEY"
  api_base_url: *volcengine_endpoint
  max_tokens: 32000
  context_window: 256000
  pricing_currency: "짜"
  models:
    doubao-seed-1.6:
      id: "doubao-seed-1-6-250615"
      name: "Doubao Seed 1.6"
      pricing: { input: 0.80, output: 2.00 }
    doubao-pro-32k:
      id: "doubao-pro-32k"
      name: "Doubao Pro 32K"
      pricing: { input: 0.80, output: 2.00 }

openai-openrouter:
  name: "OpenAI (via OpenRouter)"
  api_key_env_var: "OPENAI_API_KEY_OPENROUTER"
  api_base_url: *openrouter_endpoint
  max_tokens: 16384
  context_window: 128000
  pricing_currency: "$"
  models:
    gpt-4o-or:
      id: "openai/gpt-4o"
      name: "GPT-4o"
      pricing: { input: 2.5, output: 10.00 }
    gpt-4o-mini-or:
      id: "openai/gpt-4o-mini"
      name: "GPT-4o Mini"
      pricing: { input: 0.15, output: 0.60 }

anthropic-openrouter:
  name: "Anthropic (via OpenRouter)"
  api_key_env_var: "ANTHROPIC_API_KEY_OPENROUTER"
  api_base_url: *openrouter_endpoint
  max_tokens: 64000
  context_window: 200000
  pricing_currency: "$"
  rate_limit:
    min_interval_seconds: 1.0
    max_requests_per_minute: 30
  models:
    claude-sonnet-4-or:
      id: "anthropic/claude-sonnet-4"
      name: "Claude Sonnet 4"
      pricing: { input: 3.00, output: 15.00 }
    claude-3.5-sonnet-or:
      id: "anthropic/claude-3.5-sonnet"
      name: "Claude 3.5 Sonnet"
      pricing: { input: 3.00, output: 15.00 }

# Custom endpoint - user can configure any OpenAI-compatible API
custom:
  name: "Custom Endpoint"
  api_key_env_var: ""
  api_base_url: ""
  max_tokens: 4096
  context_window: 128000
  pricing_currency: "$"
  models: {}
